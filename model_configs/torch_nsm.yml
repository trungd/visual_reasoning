backend: pytorch
model:
  name: src.torch.models.nsm.NSM
  embed_dim: 300
  encoder:
    type: lstm
  decoder:
    type: lstm
  num_steps: 8
  dropout: 0.15
dataset:
  name: src.torch.datasets.gqa.GQA
train:
  num_epochs: 15
  optimizer:
    name: adam
    gamma: 1e-4